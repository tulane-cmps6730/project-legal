{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Let's start playing around with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 22:53:23.797661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-14 22:53:25.278915: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset,Dataset,DatasetDict\n",
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification,AutoTokenizer,Trainer,TrainingArguments,AutoModel,AutoConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in training data\n",
    "This dataset contains 100 annotated terms of service contracts, each row represents a sentence, which carries on it a label. The label corresponds to a different type of potential unfairness, as defined by the authors of CLAUDETTE, the previous paper from which this dataset came from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A</th>\n",
       "      <th>CH</th>\n",
       "      <th>CR</th>\n",
       "      <th>J</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LTD</th>\n",
       "      <th>PINC</th>\n",
       "      <th>TER</th>\n",
       "      <th>USE</th>\n",
       "      <th>document</th>\n",
       "      <th>document_ID</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>TER_targets</th>\n",
       "      <th>LTD_targets</th>\n",
       "      <th>A_targets</th>\n",
       "      <th>CH_targets</th>\n",
       "      <th>CR_targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>websites &amp; communications terms of use</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>please read the terms of this entire document ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>by accessing or signing up to receive communic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>our websites include multiple domains such as ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you may also recognize our websites by nicknam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  A  CH  CR  J  LAW  LTD  PINC  TER  USE document  document_ID  \\\n",
       "0           0  0   0   0  0    0    0     0    0    0  Mozilla            0   \n",
       "1           1  0   0   0  0    0    0     0    0    0  Mozilla            0   \n",
       "2           2  0   0   0  0    0    0     0    0    1  Mozilla            0   \n",
       "3           3  0   0   0  0    0    0     0    0    0  Mozilla            0   \n",
       "4           4  0   0   0  0    0    0     0    0    0  Mozilla            0   \n",
       "\n",
       "   label                                               text TER_targets  \\\n",
       "0      0             websites & communications terms of use         NaN   \n",
       "1      0  please read the terms of this entire document ...         NaN   \n",
       "2      1  by accessing or signing up to receive communic...         NaN   \n",
       "3      0  our websites include multiple domains such as ...         NaN   \n",
       "4      0  you may also recognize our websites by nicknam...         NaN   \n",
       "\n",
       "  LTD_targets A_targets CH_targets CR_targets  \n",
       "0         NaN       NaN        NaN        NaN  \n",
       "1         NaN       NaN        NaN        NaN  \n",
       "2         NaN       NaN        NaN        NaN  \n",
       "3         NaN       NaN        NaN        NaN  \n",
       "4         NaN       NaN        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load in a pretrained huggingface BERT model  (https://huggingface.co/pile-of-law/legalbert-large-1.7M-2) to get the word embeddings of each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('pile-of-law/legalbert-large-1.7M-2')\n",
    "model = BertModel.from_pretrained('pile-of-law/legalbert-large-1.7M-2')\n",
    "model.to(device)\n",
    "text = \"This is a test\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input.to(device))\n",
    "weights = model.get_input_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.pooler_output.shape\n",
    "output.pooler_output[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample the training data\n",
    "Since our classifier isn't returning any positive predictions, the problem could be that it isn't seeing enough examples of sentences that are potentially exploitative. Let's fix that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "x, y = df['text'], df['label']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "ros = RandomOverSampler(random_state=42,sampling_strategy=.5)\n",
    "x_train_res, y_train_res = ros.fit_resample(pd.DataFrame(x_train), pd.DataFrame(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(x_train,y_train,left_index=True,right_index=True)\n",
    "train_os_df = pd.merge(x_train_res,y_train_res,left_index=True,right_index=True)\n",
    "test_df = pd.merge(x_test,y_test,left_index=True,right_index=True)\n",
    "train_os_df.reset_index(inplace=True)\n",
    "test_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'text', 'label'],\n",
       "    num_rows: 4084\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = Dataset.from_pandas(train)\n",
    "train_os = Dataset.from_pandas(train_os_df.sample(frac = .5))\n",
    "test = Dataset.from_pandas(test_df)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__'],\n",
       "    num_rows: 16333\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'text', 'label', '__index_level_0__'],\n",
       "    num_rows: 10952\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 16333\n",
       "    })\n",
       "    train_os: Dataset({\n",
       "        features: ['index', 'text', 'label', '__index_level_0__'],\n",
       "        num_rows: 10952\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['index', 'text', 'label'],\n",
       "        num_rows: 2042\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['index', 'text', 'label'],\n",
       "        num_rows: 2042\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_valid = test.train_test_split(test_size=0.5,seed=42)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train':train,\n",
    "    'train_os':train_os,\n",
    "    'test':test_valid['test'],\n",
    "    'validation':test_valid['train']\n",
    "    })\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820db741935242569cb08e1c53f25035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2f849fcfb5429da84703a6dc80adb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10952 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44b642e8444432ca179e1a9c3164f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e605ee54894fd2a8012b5081f967d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_df = dataset_dict.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 16333\n",
       "    })\n",
       "    train_os: Dataset({\n",
       "        features: ['index', 'text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 10952\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['index', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2042\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['index', 'text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2042\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df.set_format('torch', columns=['input_ids', 'attention_mask',\"token_type_ids\",'label'])\n",
    "#data collator forms a batch with padding for the length of the longest input. We do this so we don't need to repeat unnecessary computations on a global maximum length\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's construct a custom classifier classifier to classify sentences as potentially unfair or not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_v1(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(Classifier_v1,self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_name,config = AutoConfig.from_pretrained(model_name,\n",
    "                                                                                              output_attention = True,\n",
    "                                                                                              output_hidden_state = True))\n",
    "        # New Layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = nn.Linear(self.model.config.hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, input = None, attention_mask = None, token_type_ids = None,input_ids = None, labels = None):\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids=input_ids, attention_mask = attention_mask, token_type_ids = token_type_ids)\n",
    "        pooler_output = outputs.pooler_output[0]\n",
    "        output = self.hidden(pooler_output)\n",
    "        logit = self.sigmoid(output)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_df['train'], shuffle=True, batch_size=1, collate_fn=data_collator\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_df['test'], shuffle=True, batch_size=1,collate_fn=data_collator\n",
    ")\n",
    "train_os_dataloader = DataLoader(\n",
    "    tokenized_df['train_os'], shuffle=True, batch_size=1, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "model_v2 = Classifier_v1('pile-of-law/legalbert-large-1.7M-2').to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = Adam(model_v2.parameters(),lr =.0001)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = epochs * len(train_dataloader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    'linear',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,train_dataloader,epochs,loss_fn,optimizer,lr_scheduler,testing=False):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in tqdm.tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            label = batch['labels'].to(torch.float32).to(device)\n",
    "            output = model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "            loss = loss_fn(output,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for i,batch in tqdm.tqdm(enumerate(test_dataloader)):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            label = batch['labels'].to(torch.float32).to(device)\n",
    "            with torch.no_grad():\n",
    "                output = model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "            loss = loss_fn(output,label)\n",
    "            pred = torch.round(output)\n",
    "            preds.append(pred.detach().cpu().numpy())\n",
    "            labels.append(batch[\"labels\"].detach().cpu().numpy())\n",
    "        print(f\"Epoch: {epoch + 1} | Accuracy: {accuracy_score(labels,preds)} | Precision: {precision_score(labels,preds)} | Recall: {recall_score(labels,preds)} | F1: {f1_score(labels,preds)} | Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_dataloader,loss_fn):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for i,batch in tqdm.tqdm(enumerate(test_dataloader)):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        label = batch['labels'].to(torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "        loss = loss_fn(output,label)\n",
    "        pred = torch.round(output)\n",
    "        preds.append(pred.detach().cpu().numpy())\n",
    "        labels.append(batch[\"labels\"].detach().cpu().numpy())\n",
    "    print(f\"Accuracy: {accuracy_score(labels,preds)} | Precision: {precision_score(labels,preds)} | Recall: {recall_score(labels,preds)} | F1: {f1_score(labels,preds)} | Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10952/10952 [16:16<00:00, 11.21it/s] \n",
      "2042it [02:54, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Accuracy: 0.8555337904015671 | Precision: 0.369281045751634 | Recall: 0.5255813953488372 | F1: 0.43378119001919385 | Loss: 0.42886269092559814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10952/10952 [16:17<00:00, 11.20it/s]\n",
      "2042it [03:25,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Accuracy: 0.8501469147894222 | Precision: 0.34983498349834985 | Recall: 0.4930232558139535 | F1: 0.4092664092664093 | Loss: 0.34930482506752014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10952/10952 [15:49<00:00, 11.53it/s]\n",
      "2042it [02:50, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Accuracy: 0.8672869735553379 | Precision: 0.39705882352941174 | Recall: 0.5023255813953489 | F1: 0.44353182751540043 | Loss: 0.44554612040519714\n"
     ]
    }
   ],
   "source": [
    "train(model_v2,train_os_dataloader,3,loss_fn,optimizer,lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_v2.state_dict(),'../models/model_v2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(\n",
    "    tokenized_df['validation'], shuffle=True, batch_size=1,collate_fn=data_collator\n",
    ")\n",
    "test(model_v2,test_dataloader,loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Training Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model is simply labeling everything as not exploitative, which would explain why our f1 score is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
